/**
 * ðŸ¤– ServiÃ§o de Conversa por Voz com IA
 * Integra STT + IA + TTS para conversaÃ§Ã£o natural
 */

import { logger } from './logger.js';
import { externalLLMService } from './ExternalLLMService.js';
import { externalVoiceService } from './ExternalVoiceService.js';

class VoiceConversationService {
  constructor() {
    this.conversationHistory = new Map(); // userId -> history
    this.activeConversations = new Set(); // userId em conversa ativa
  }

  /**
   * ðŸ§  Processar conversa com IA LLM Externa
   */
  async processWithAI(userId, text, context = {}) {
    try {
      logger.info(`ðŸ§  Processando com IA LLM: "${text}"`);

      // Obter histÃ³rico da conversa
      const history = this.conversationHistory.get(userId) || [];
      
      // Construir contexto para a API LLM
      let contextText = 'VocÃª Ã© MaryBot, um assistente de voz amigÃ¡vel para Discord. ';
      contextText += 'Responda de forma natural, breve e conversacional em portuguÃªs brasileiro. ';
      contextText += 'Esta Ã© uma conversa por voz, entÃ£o mantenha as respostas concisas.';
      
      // Adicionar histÃ³rico recente
      if (history.length > 0) {
        contextText += '\n\nHistÃ³rico da conversa:';
        history.slice(-3).forEach(msg => {
          const role = msg.role === 'user' ? 'UsuÃ¡rio' : 'VocÃª';
          contextText += `\n${role}: ${msg.content}`;
        });
      }
      
      // Gerar resposta usando API LLM externa
      const aiResult = await externalLLMService.generateConversation({
        prompt: text,
        context: contextText,
        maxTokens: 100, // Mais conciso para voz
        userId: userId
      });
      
      if (aiResult.response && aiResult.response.trim()) {
        // Atualizar histÃ³rico
        this.updateConversationHistory(userId, text, aiResult.response);
        
        logger.success(`âœ… IA LLM respondeu: "${aiResult.response.substring(0, 50)}..."`);
        return {
          success: true,
          response: aiResult.response,
          confidence: 0.9,
          source: 'external_llm'
        };
      }

      throw new Error('API LLM nÃ£o gerou resposta vÃ¡lida');

    } catch (error) {
      logger.warn(`âš ï¸ Erro na IA: ${error.message}`);
      return null;
    }
  }

  /**
   * ðŸ’« Gerar resposta contextual inteligente
   */
  async generateContextualResponse(userId, text, guildInfo = {}) {
    try {
      // Tentar processar com IA primeiro
      const aiResponse = await this.processWithAI(userId, text, guildInfo);
      if (aiResponse && aiResponse.success) {
        return aiResponse;
      }

      // Fallback para respostas programadas mais inteligentes
      return this.generateSmartFallbackResponse(userId, text);

    } catch (error) {
      logger.error('âŒ Erro na geraÃ§Ã£o de resposta contextual:', error);
      return this.generateBasicResponse(text);
    }
  }

  /**
   * ðŸ§© Resposta fallback inteligente
   */
  generateSmartFallbackResponse(userId, text) {
    const lowerText = text.toLowerCase();
    
    // AnÃ¡lise de sentimento bÃ¡sica
    const sentiment = this.analyzeSentiment(text);
    
    // Respostas baseadas em sentimento
    if (sentiment === 'positive') {
      const positiveResponses = [
        'Que legal! Fico feliz em saber disso!',
        'Adorei ouvir isso! VocÃª parece animado!',
        'Que Ã³timo! Me conte mais sobre isso!'
      ];
      return {
        success: true,
        response: positiveResponses[Math.floor(Math.random() * positiveResponses.length)],
        confidence: 0.7,
        source: 'sentiment-positive'
      };
    }
    
    if (sentiment === 'negative') {
      const supportiveResponses = [
        'Sinto muito por isso. Quer conversar sobre o que estÃ¡ acontecendo?',
        'Parece que vocÃª nÃ£o estÃ¡ se sentindo muito bem. Como posso te ajudar?',
        'Ã€s vezes as coisas podem ser difÃ­ceis. Estou aqui se precisar de alguÃ©m para conversar.'
      ];
      return {
        success: true,
        response: supportiveResponses[Math.floor(Math.random() * supportiveResponses.length)],
        confidence: 0.7,
        source: 'sentiment-negative'
      };
    }

    // Respostas por categorias de interesse
    if (lowerText.includes('jogo') || lowerText.includes('game')) {
      return {
        success: true,
        response: 'VocÃª gosta de jogos? Eu posso te ajudar com vÃ¡rios jogos aqui no servidor! Quer que eu te mostre?',
        confidence: 0.8,
        source: 'topic-games'
      };
    }

    if (lowerText.includes('mÃºsica') || lowerText.includes('music')) {
      return {
        success: true,
        response: 'MÃºsica Ã© incrÃ­vel! Eu adoraria poder ouvir mÃºsica tambÃ©m. Qual Ã© seu estilo favorito?',
        confidence: 0.8,
        source: 'topic-music'
      };
    }

    // Resposta padrÃ£o mais inteligente
    return {
      success: true,
      response: 'Interessante! Me conte mais sobre isso. Adoro conversar!',
      confidence: 0.5,
      source: 'fallback-smart'
    };
  }

  /**
   * ðŸ“Š AnÃ¡lise de sentimento bÃ¡sica
   */
  analyzeSentiment(text) {
    const positiveWords = ['feliz', 'Ã³timo', 'legal', 'bom', 'incrÃ­vel', 'adorei', 'perfeito'];
    const negativeWords = ['triste', 'ruim', 'chato', 'difÃ­cil', 'problema', 'erro', 'odiar'];
    
    const lowerText = text.toLowerCase();
    
    let positiveCount = 0;
    let negativeCount = 0;
    
    positiveWords.forEach(word => {
      if (lowerText.includes(word)) positiveCount++;
    });
    
    negativeWords.forEach(word => {
      if (lowerText.includes(word)) negativeCount++;
    });
    
    if (positiveCount > negativeCount) return 'positive';
    if (negativeCount > positiveCount) return 'negative';
    return 'neutral';
  }

  /**
   * ðŸ”„ Atualizar histÃ³rico de conversa
   */
  updateConversationHistory(userId, userMessage, botResponse) {
    if (!this.conversationHistory.has(userId)) {
      this.conversationHistory.set(userId, []);
    }
    
    const history = this.conversationHistory.get(userId);
    
    // Adicionar mensagens com timestamp
    history.push({
      type: 'user',
      message: userMessage,
      timestamp: Date.now()
    });
    
    history.push({
      type: 'bot',
      message: botResponse,
      timestamp: Date.now()
    });
    
    // Manter apenas Ãºltimas 20 mensagens
    if (history.length > 20) {
      history.splice(0, history.length - 20);
    }
  }

  /**
   * ðŸ§¼ Limpar histÃ³rico expirado
   */
  cleanExpiredHistory() {
    const expiredTime = Date.now() - (30 * 60 * 1000); // 30 minutos
    
    for (const [userId, history] of this.conversationHistory.entries()) {
      const validHistory = history.filter(msg => msg.timestamp > expiredTime);
      
      if (validHistory.length === 0) {
        this.conversationHistory.delete(userId);
      } else {
        this.conversationHistory.set(userId, validHistory);
      }
    }
  }

  /**
   * ðŸ“ˆ Status do serviÃ§o
   */
  getStatus() {
    return {
      activeConversations: this.activeConversations.size,
      totalUsers: this.conversationHistory.size,
      aiServerUrl: this.aiServerUrl
    };
  }

  /**
   * ðŸ§  Resposta bÃ¡sica de emergÃªncia
   */
  generateBasicResponse(text) {
    return {
      success: true,
      response: 'Desculpe, estou com um pouco de dificuldade para processar isso agora. Pode repetir de outra forma?',
      confidence: 0.3,
      source: 'basic-fallback'
    };
  }
}

// InstÃ¢ncia singleton
export const voiceConversationService = new VoiceConversationService();

export { VoiceConversationService };